{"cells":[{"cell_type":"markdown","metadata":{"id":"5UtdbaBpE3YT"},"source":["**Name: Mohammad Bagher Soltani**\n","\n","**Std. No.: 98105813**"]},{"cell_type":"markdown","metadata":{"id":"u8XrtOBu1RD_"},"source":["# 0. Introduction"]},{"cell_type":"markdown","metadata":{"id":"VtC8ShqGz19c"},"source":["In this notebook, we aim to make a classifier to identify spam messages. We will use a dataset that is consisted of 5000 SMS texts. Some of theses texts are labeled as `spam` while the rest are considered `ham`.\n","\n","For this aim, we will use **BERT** word-embeddings from the `transformers` library. We will not train a transformer, as it requires a lot of GPU power, but we will fine-tune a pre-trained transformer encoder (**BERT**) for our classification problem.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2887,"status":"ok","timestamp":1673018358209,"user":{"displayName":"M Soltani","userId":"16515952197003346495"},"user_tz":-210},"id":"QXKDxP749KG7","outputId":"84e1de97-8f2f-48c6-9eb6-95d795f3342d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7,"status":"ok","timestamp":1673018363018,"user":{"displayName":"M Soltani","userId":"16515952197003346495"},"user_tz":-210},"id":"vr_OQ3tf9NAJ","outputId":"82706d11-ed12-42ff-ca88-6f88a22e86fa"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/Deep Learning HW4\n"]}],"source":["%cd '/content/drive/MyDrive/Deep Learning HW4'"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10794,"status":"ok","timestamp":1673017831497,"user":{"displayName":"M Soltani","userId":"16515952197003346495"},"user_tz":-210},"id":"mUv6qR8uoGB0","outputId":"5f101169-f3f5-44dd-d32b-61b4b68725db"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install --quiet transformers torch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RDKTDFwm1oSY"},"outputs":[],"source":["# IMPORTS\n","from math import ceil\n","\n","import pandas as pd\n","import numpy as np\n","\n","from tqdm import tqdm\n","from copy import deepcopy\n","\n","import torch\n","import torch.nn as nn\n","\n","from transformers import BertTokenizer, BertModel\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mdql46FiJgKB"},"outputs":[],"source":["device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{"id":"Ur81S9OI1X4D"},"source":["# 1. Data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8a0ay6ADwhBT"},"outputs":[],"source":["df = pd.read_csv('spam.csv', encoding='latin-1')\n","df = df.drop(['Unnamed: 2','Unnamed: 3','Unnamed: 4'],axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1673018382655,"user":{"displayName":"M Soltani","userId":"16515952197003346495"},"user_tz":-210},"id":"7SXFPoDdx1jP","outputId":"07885d81-0291-4b34-96fd-1aed36f9f782"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-89c5b271-1ad3-48a8-b5ac-46eafbb21a0e\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>ham</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>ham</td>\n","      <td>Ok lar... Joking wif u oni...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>spam</td>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>ham</td>\n","      <td>U dun say so early hor... U c already then say...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>ham</td>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-89c5b271-1ad3-48a8-b5ac-46eafbb21a0e')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-89c5b271-1ad3-48a8-b5ac-46eafbb21a0e button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-89c5b271-1ad3-48a8-b5ac-46eafbb21a0e');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["  label                                               text\n","0   ham  Go until jurong point, crazy.. Available only ...\n","1   ham                      Ok lar... Joking wif u oni...\n","2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n","3   ham  U dun say so early hor... U c already then say...\n","4   ham  Nah I don't think he goes to usf, he lives aro..."]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"elapsed":630,"status":"ok","timestamp":1673018390740,"user":{"displayName":"M Soltani","userId":"16515952197003346495"},"user_tz":-210},"id":"gcVqsZZT8eaK","outputId":"b8120abd-6de8-4259-d84f-617533f59bed"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-fc3cb148-a0bc-4338-b04f-1ae745fdccd3\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Go until jurong point, crazy.. Available only ...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>Ok lar... Joking wif u oni...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>U dun say so early hor... U c already then say...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>Nah I don't think he goes to usf, he lives aro...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fc3cb148-a0bc-4338-b04f-1ae745fdccd3')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-fc3cb148-a0bc-4338-b04f-1ae745fdccd3 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-fc3cb148-a0bc-4338-b04f-1ae745fdccd3');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["   label                                               text\n","0      0  Go until jurong point, crazy.. Available only ...\n","1      0                      Ok lar... Joking wif u oni...\n","2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n","3      0  U dun say so early hor... U c already then say...\n","4      0  Nah I don't think he goes to usf, he lives aro..."]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["######################   TODO 1.1   ########################\n","# change the label column so that `spam` labels get `1` \n","# and `ham` gets `0`\n","###################### (2 points) ##########################\n","df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HC6Ll3VS9iJo"},"outputs":[],"source":["######################   TODO 1.2   ########################\n","# split the dataframe into two sections of train and val. \n","# keep the train size 10 times of val.\n","###################### (3 points) ##########################\n","data_split = train_test_split(df, test_size=0.1, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9-B7gl1O79Wx"},"outputs":[],"source":["######################   TODO 1.3   ########################\n","# based on what you did in homework 1, create a dataset and \n","# a dataloader. Your dataset should return a text with its \n","# respective label when iterated.\n","###################### (10 points) ##########################\n","\n","class CustomDataset:\n","    def __init__(self, df):\n","        self.data = df['text'].values\n","        self.labels = df['label'].values\n","\n","    def __getitem__(self, index):\n","        return self.data.iloc[index], self.labels.iloc[index]\n","    \n","    def __len__(self):\n","        return len(self.data)\n","\n","\n","class CustomDataloader:\n","    def __init__(self, dataset, batch_size, shuffle=False):\n","        self.dataset = dataset\n","        self.batch_size = batch_size\n","        self.indexes = np.arange(len(dataset))\n","        if shuffle:\n","            np.random.shuffle(self.indexes)\n","\n","    def __len__(self):\n","        return len(self.dataset) // self.batch_size\n","\n","    def __iter__(self, calm=True):\n","        for i in range(len(self)):\n","            start = i * self.batch_size\n","            end = start + self.batch_size\n","            idx = self.indexes[start:end]\n","            batch = self.dataset[idx]\n","            \n","            yield batch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lFj6H3L19yYh"},"outputs":[],"source":["######################   TODO 1.4   ########################\n","# initialize a dataloader for each of your train and val\n","# splits.\n","###################### (5 points) ##########################\n","train_ds = CustomDataset(data_split[0])\n","val_ds = CustomDataset(data_split[1])\n","\n","batch_size = 100\n","train_dl = CustomDataloader(train_ds, batch_size, shuffle=True)\n","val_dl = CustomDataloader(val_ds, batch_size, shuffle=True)"]},{"cell_type":"markdown","metadata":{"id":"Onghqm9A-DlN"},"source":["# 2. Pretrained Language Model"]},{"cell_type":"markdown","metadata":{"id":"OJSHF9OK-H7t"},"source":["In this section we will use the pretrained **BERT** model from the `transformers` library with its respective `tokenizer`. **BERT** is a transformer encoder which is suited for various downstream NLP tasks namely *Sequence classification*."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":217,"referenced_widgets":["7e5f69d9c7684857bded76c6fea9ebba","dfc4b9f437324ae8aaa8279571f0cafb","553e4c290bf442499971d293d9b51ae2","f8238db21d4f456ca81a0095269a79a9","356c151b038c4ddd827fc6fc7ccceb35","e5e43ab17bf04256a57146f0ee4d20d3","d7acd4a9f756495bb73c4f81843c7c01","2602765530cc477aaefa2a609aa83e68","47b492f17b554b4ca54cc2a73f513872","7d24ad7402a54f99ace407a8636b075e","681bf438ba224d32a824bb2331827b64","864539d99caf439f9cbdc6c71777502e","a4a8c2aad378492d87bd5d34bbe09c71","0989e4870fb841e39037a72a11751e86","57431a90f3e447e98518973a7cb48c07","c1dc87cf80174e94beda03713900d47f","fa1a6136434f46a68e787410b4101991","6c139070deaa4927a5f6d8ac34065cf0","2708320d5e94424e81b868cde9635d8a","7cb945c0f6854e8091736b96c9ce80d9","18948547f6b3494487cdd01a4e4ef40f","795090105206442dbecd9be390c79c01","04298fc83d2b4a4aab01555fd98474f4","c857146f435247658cb6e72f82f48715","a146bfcfbd464397a8fee3cab82b25b1","8a2d9f0de4064791ab8ede7140e37e4c","d847035518044d78b1a4942907cfa2f9","2eba24d68f4347da919c7c0e7665c4ab","cfe5b4060c124dbbb647e34fb590661a","b44b6301f7094dabb50f455e65c19bb1","a42bb6d71aa343c5adb92fc1ced2b694","2008e9e839f74eefb4e456b74a4ed8db","b53dcd103db54ab28e675e5f739c74cc","beb26ac9783b4619bfcc8271bf196757","0ca6457b9991475b9da90b3c21710370","6f6f3426be5f421eb0265274021791ec","422990b585a74174bdf99865c56ccd53","166cb4fb73944407be4145d3c9a3c691","87beb12ec22a433f8c536ae39759244a","8eb800a03d0e47e79dd790b08db191e5","8d99d91ac49541a5abfa34be93a6c893","fdea909831df49329811bf23b60c390d","e27a087398244656979bc31af17b0660","7653bb5066a641fd9f9460e8a0ba9a9c"]},"executionInfo":{"elapsed":11728,"status":"ok","timestamp":1672866512532,"user":{"displayName":"M Soltani","userId":"16515952197003346495"},"user_tz":-210},"id":"wYJGf9Thu2Cp","outputId":"e514df76-214a-4233-e39e-22de70fbb468"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7e5f69d9c7684857bded76c6fea9ebba","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"864539d99caf439f9cbdc6c71777502e","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"04298fc83d2b4a4aab01555fd98474f4","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"beb26ac9783b4619bfcc8271bf196757","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["# Defining the tokenizer and model\n","bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","bert_model = BertModel.from_pretrained(\"bert-base-uncased\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":621,"status":"ok","timestamp":1672866513116,"user":{"displayName":"M Soltani","userId":"16515952197003346495"},"user_tz":-210},"id":"Gi7zqd_WybLR","outputId":"a1abc3e1-a898-4652-e2db-e2cd596479d9"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([1, 768])\n"]}],"source":["text = \"What is your name?\"\n","tokenized = bert_tokenizer(text, max_length=128, padding=\"max_length\", truncation=True, return_tensors='pt')\n","encoding = bert_model(**tokenized)\n","print(encoding.pooler_output.shape)"]},{"cell_type":"markdown","metadata":{"id":"_cO5AxMY_jut"},"source":["**TODO 2.1.** In section bellow, try to explain the arguments that `bert_tokenizer` gets as input. (text, max_length, padding, truncation, return_tensors) *(10 points)*"]},{"cell_type":"markdown","metadata":{"id":"kBbLb7UG_8Oj"},"source":["<font color=red>\n","text: sequence of words to be tokenized.\n","<br>\n","<br>\n","max_length: controls the maximum length of the input sequence. Here, length\n","<br>\n","means the number of tokens that can be derived from the sequence.\n","<br>\n","<br>\n","padding: specifies how padding should be implemented. setting to \"max_length\"\n","<br>\n","will add [PAD] token to the end of the sentence so that its length becomes\n","<br>\n","max_length - 2. (two other tokens are [CLS] and [SEP] which are put at\n","<br>\n","the start and end of the tokens). Setting to \"longest\" will add padding\n","<br>\n","tokens so that the length of the sequence becomes equal to that of\n","<br>\n","the longest sequence.\n","<br>\n","<br>\n","truncation: if the length of the sequence exceeds max_length-2, remove\n","<br>\n","the rest of the tokens so that it becomes max_length-2. \n","<br>\n","<br>\n","return_tensors: if not set, returns ordinary python list of intergers.\n","<br>\n","Otherwise, returns tensors. 'tf' is for tensorflow.constant, 'pt' is \n","<br>\n","for torch.Tensor, 'np' is for numpy.ndarray.\n","</font>\n"]},{"cell_type":"markdown","metadata":{"id":"ch8y4w-yBskU"},"source":["# 3. Model"]},{"cell_type":"markdown","metadata":{"id":"sqktej-9B39V"},"source":["If you inspect the `encoding` of the `BERT`, you will realize that `BERT` gives a vector for each of the tokens included in the input sentence. However, all of these word tokens are not needed for a simple classification task.\n","\n","Instead, we can use the first token representation, as it captures the whole tokens meanings. `BERT` provides this token for us in a special variable called `pooler_output`. We will use this `pooler_output` as the input of our classification head inside our classifier model.\n","![BERT pooler output](https://miro.medium.com/max/1100/1*Or3YV9sGX7W8QGF83es3gg.webp)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"65p2L9_zyjHW"},"outputs":[],"source":["class SpamClassifier(nn.Module):\n","    def __init__(self, embedding_tokenizer, embedding_model):\n","        super().__init__()\n","        ######################   TODO 3.1   ########################\n","        # construct layers and structure of the network\n","        self.embedding_size = 768\n","\n","        self.tokenizer = embedding_tokenizer\n","        self.embedding = embedding_model\n","        self.classifier = nn.Linear(self.embedding_size, 1)\n","        self.sigmoid = nn.Sigmoid()\n","        ###################### (10 points) #########################\n","\n","    def forward(self, x):\n","        ######################   TODO 3.2   ########################\n","        # implement the forward pass of your model. first tokenizer\n","        # the sentence, the get the embeddings from your language\n","        # model, then use the `pooler_output` for your classifier\n","        # layer.\n","        tokenized = self.tokenizer(x, max_length=128, padding=\"max_length\", truncation=True, return_tensors='pt')\n","        tokenized = tokenized.to(device)\n","        encoding = self.embedding(**tokenized)\n","        pooler_output = encoding.pooler_output\n","        output = self.sigmoid(self.classifier(pooler_output))\n","        output = output.squeeze(1)\n","        return output\n","        ###################### (10 points) #########################\n","\n","    def predict(self, x):\n","        ######################   TODO 3.3   ########################\n","        # get the predicted class of x.\n","        output = self(x)\n","        prediction = output.round()\n","        return prediction\n","        ###################### (5 points) #########################"]},{"cell_type":"markdown","metadata":{"id":"ubb_GkQBBwId"},"source":["# 4. Training and Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1490,"status":"ok","timestamp":1672842744638,"user":{"displayName":"M Soltani","userId":"16515952197003346495"},"user_tz":-210},"id":"OcMj49f8686B","outputId":"407d14bc-b567-4ef6-9fef-4aa4f191e512"},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]}],"source":["######################   TODO 4.1   ########################\n","# define the learning parameters here (lr and epochs.)\n","# then initilizer your model, an appropriate optimizer\n","# and loss function.\n","lr = 1e-4\n","epochs = 2\n","\n","embedding_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","embedding_model = BertModel.from_pretrained(\"bert-base-uncased\")\n","\n","model = SpamClassifier(embedding_tokenizer, embedding_model).to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr)\n","criterion = nn.BCELoss()\n","###################### (10 points) ##########################"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":776689,"status":"ok","timestamp":1672843521319,"user":{"displayName":"M Soltani","userId":"16515952197003346495"},"user_tz":-210},"id":"518uVqVe7Aly","outputId":"41e4d79d-9a74-4a6f-e4c5-c77a9ceedfd8"},"outputs":[{"name":"stderr","output_type":"stream","text":["Epoch 1: train_loss=0.003, train_accuracy=0.9264: 100%|██████████| 50/50 [01:32<00:00,  1.85s/it]\n","Epoch 1: val_loss=0.001, val_accuracy=0.9680: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n","Epoch 2: train_loss=0.009, train_accuracy=0.6674: 100%|██████████| 50/50 [01:33<00:00,  1.86s/it]\n","Epoch 2: val_loss=0.004, val_accuracy=0.8760: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n","Epoch 3: train_loss=0.007, train_accuracy=0.7360: 100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","Epoch 3: val_loss=0.004, val_accuracy=0.8760: 100%|██████████| 5/5 [00:03<00:00,  1.48it/s]\n","Epoch 4: train_loss=0.005, train_accuracy=0.8642: 100%|██████████| 50/50 [01:34<00:00,  1.88s/it]\n","Epoch 4: val_loss=0.006, val_accuracy=0.8760: 100%|██████████| 5/5 [00:03<00:00,  1.48it/s]\n","Epoch 5: train_loss=0.004, train_accuracy=0.8642: 100%|██████████| 50/50 [01:34<00:00,  1.90s/it]\n","Epoch 5: val_loss=0.004, val_accuracy=0.8760: 100%|██████████| 5/5 [00:03<00:00,  1.49it/s]\n","Epoch 6: train_loss=0.005, train_accuracy=0.8642: 100%|██████████| 50/50 [01:33<00:00,  1.88s/it]\n","Epoch 6: val_loss=0.004, val_accuracy=0.8760: 100%|██████████| 5/5 [00:03<00:00,  1.50it/s]\n","Epoch 7: train_loss=0.004, train_accuracy=0.8642: 100%|██████████| 50/50 [01:33<00:00,  1.87s/it]\n","Epoch 7: val_loss=0.004, val_accuracy=0.8760: 100%|██████████| 5/5 [00:03<00:00,  1.50it/s]\n","Epoch 8: train_loss=0.005, train_accuracy=0.8642: 100%|██████████| 50/50 [01:33<00:00,  1.88s/it]\n","Epoch 8: val_loss=0.005, val_accuracy=0.8760: 100%|██████████| 5/5 [00:03<00:00,  1.46it/s]\n"]}],"source":["######################   TODO 4.2   ########################\n","# implement your training loop and train your model.\n","# return to homework 1 if needed.\n","train_losses = []\n","train_accs = []\n","val_losses = []\n","val_accs = []\n","\n","best_model = None\n","best_val_loss = - np.inf\n","\n","for epoch in range(epochs):\n","  \n","  train_loss = 0\n","  total = 0\n","  correct = 0\n","  model.train()\n","  with tqdm(enumerate(train_dl), total=len(train_dl)) as pbar:\n","    for _, (data, labels) in pbar:\n","      pred = model(data)\n","      labels = torch.Tensor(labels).to(device)\n","      loss = criterion(pred, labels)\n","      train_loss += loss.detach()\n","      loss.backward()\n","      optimizer.step()\n","\n","      total += len(data)\n","      correct += (pred.round() == labels).sum()\n","\n","      pbar.set_description(f'Epoch {epoch + 1}: train_loss={(train_loss / total):.3f}, train_accuracy={(correct / total):.4f}')\n","  \n","  train_losses.append(train_loss)\n","  train_accs.append(correct / total)\n","\n","  val_loss = 0\n","  total = 0\n","  correct = 0\n","  model.eval()\n","  with torch.no_grad():\n","    with tqdm(enumerate(val_dl), total=len(val_dl)) as pbar:\n","      for _, (data, labels) in pbar:\n","        pred = model(data)\n","        labels = torch.Tensor(labels).to(device)\n","        loss = criterion(pred, labels)\n","        val_loss += loss.detach()\n","\n","        total += len(data)\n","        correct += (pred.round() == labels).sum()\n","\n","        pbar.set_description(f'Epoch {epoch + 1}: val_loss={(val_loss / total):.3f}, val_accuracy={(correct / total):.4f}')\n","  \n","  val_losses.append(val_loss)\n","  val_accs.append(correct / total)\n","  if val_loss < best_val_loss:\n","    best_val_loss = val_loss\n","    best_model = deepcopy(model)\n","\n","###################### (10 points) ##########################"]},{"cell_type":"markdown","metadata":{"id":"jmPsHMXUGILx"},"source":["# 5. Using HuggingFace"]},{"cell_type":"markdown","metadata":{"id":"-EFgSOE4GLXK"},"source":["[HuggingFace library](http://huggingface.co/) has built a nice API for NLP tasks around the transformers. To get familiar with this comrehensive library, In this section you are asked to use the huggingface `Trainer`, `Dataset`, and `BertForSequenceClassification` to do what we did above again.\n","\n","Feel free to refer to the library documentation to learn about these modules."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mSzzt0YOpumQ"},"outputs":[],"source":["!pip install --quiet datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["ee72ae874db64ab8bfe8ee225404db23","c981ba65423d430ab4134eaaf7224fa8","2671e9ceda0247838cdd66d720afd440","b98a939c00e64f7e8593e0f14943a957","fde6a0c54c2f4caa95d5c1b2a1946316","dd9c5c230fe244a492c2e3918cde9ad6","1b2f38703a6c4f39987aec236418d877","6a239a5008f4467d9d4499dfc7290926","503b78115fca442f8129d76bdeae1332","0290fd67c67a4001b3641487c2b3d459","da98e22a205541a494bdbc021ccb2be5"]},"id":"xP7RRbz5Fx16","outputId":"1baddc06-cae4-4fd9-da4c-5ec180109073","executionInfo":{"status":"ok","timestamp":1673026230001,"user_tz":-210,"elapsed":1000039,"user":{"displayName":"M Soltani","userId":"16515952197003346495"}}},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/vocab.txt\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/tokenizer_config.json\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-cased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.25.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ee72ae874db64ab8bfe8ee225404db23","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5572 [00:00<?, ?ex/s]"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/config.json\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"gradient_checkpointing\": false,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.25.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 28996\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-base-cased/snapshots/5532cc56f74641d4bb33641f5c76a55d11f846e0/pytorch_model.bin\n","Some weights of the model checkpoint at bert-base-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n","PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n","/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 5014\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 1881\n","  Number of trainable parameters = 108311810\n"]},{"data":{"text/html":["\n","    <div>\n","      \n","      <progress value='524' max='1881' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [ 524/1881 06:26 < 16:44, 1.35 it/s, Epoch 0.83/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.081000</td>\n","    </tr>\n","  </tbody>\n","</table><p>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Saving model checkpoint to tmp_trainer/checkpoint-500\n","Configuration saved in tmp_trainer/checkpoint-500/config.json\n","Model weights saved in tmp_trainer/checkpoint-500/pytorch_model.bin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1881' max='1881' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1881/1881 23:06, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>500</td>\n","      <td>0.081000</td>\n","    </tr>\n","    <tr>\n","      <td>1000</td>\n","      <td>0.036500</td>\n","    </tr>\n","    <tr>\n","      <td>1500</td>\n","      <td>0.017700</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to tmp_trainer/checkpoint-1000\n","Configuration saved in tmp_trainer/checkpoint-1000/config.json\n","Model weights saved in tmp_trainer/checkpoint-1000/pytorch_model.bin\n","Saving model checkpoint to tmp_trainer/checkpoint-1500\n","Configuration saved in tmp_trainer/checkpoint-1500/config.json\n","Model weights saved in tmp_trainer/checkpoint-1500/pytorch_model.bin\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=1881, training_loss=0.037321191085012334, metrics={'train_runtime': 1387.3032, 'train_samples_per_second': 10.843, 'train_steps_per_second': 1.356, 'total_flos': 3957716494725120.0, 'train_loss': 0.037321191085012334, 'epoch': 3.0})"]},"metadata":{},"execution_count":37}],"source":["######################   TODO 5.1   ########################\n","# use huggingface Trainer and Dataset API and train the \n","# `SpamClassifier`. You should not use the `SpamClassifier`\n","# we implemented previously. Instead you should use \n","# `BertForSequenceClassification` here.\n","###################### (25 points) #########################\n","from datasets import Dataset, load_metric\n","from transformers import Trainer, BertForSequenceClassification, BertTokenizer\n","from torch.utils.data import DataLoader\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n","ds = Dataset.from_pandas(df)\n","\n","def tokenize_fn(example):\n","  return tokenizer(example[\"text\"], padding=\"max_length\", truncation=True)\n","\n","tokenized_ds = ds.map(tokenize_fn).remove_columns(column_names=[\"text\"])\n","split_ds = tokenized_ds.train_test_split(test_size=0.1)\n","\n","metric = load_metric('accuracy')\n","\n","def compute_metrics(eval_pred):\n","  predictions, labels = eval_pred\n","  predictions = np.round(predictions, axis=-1)\n","  results = metric.compute(predictions=predictions, references=labels)\n","  return results\n","\n","\n","model = BertForSequenceClassification.from_pretrained('bert-base-cased')\n","train_dataset = split_ds[\"train\"]\n","eval_dataset = split_ds[\"test\"]\n","\n","trainer = Trainer(\n","    model=model,\n","    train_dataset=train_dataset, \n","    eval_dataset=eval_dataset,\n","    compute_metrics=compute_metrics\n","    )\n","trainer.train()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"base","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"vscode":{"interpreter":{"hash":"4505c32f76012c632bc1937466981275dc824c4a4bf8fed43f9e38cd69a6e7a6"}},"widgets":{"application/vnd.jupyter.widget-state+json":{"04298fc83d2b4a4aab01555fd98474f4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c857146f435247658cb6e72f82f48715","IPY_MODEL_a146bfcfbd464397a8fee3cab82b25b1","IPY_MODEL_8a2d9f0de4064791ab8ede7140e37e4c"],"layout":"IPY_MODEL_d847035518044d78b1a4942907cfa2f9"}},"0989e4870fb841e39037a72a11751e86":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2708320d5e94424e81b868cde9635d8a","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7cb945c0f6854e8091736b96c9ce80d9","value":28}},"0ca6457b9991475b9da90b3c21710370":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_87beb12ec22a433f8c536ae39759244a","placeholder":"​","style":"IPY_MODEL_8eb800a03d0e47e79dd790b08db191e5","value":"Downloading: 100%"}},"166cb4fb73944407be4145d3c9a3c691":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18948547f6b3494487cdd01a4e4ef40f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2008e9e839f74eefb4e456b74a4ed8db":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2602765530cc477aaefa2a609aa83e68":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2708320d5e94424e81b868cde9635d8a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2eba24d68f4347da919c7c0e7665c4ab":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"356c151b038c4ddd827fc6fc7ccceb35":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"422990b585a74174bdf99865c56ccd53":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e27a087398244656979bc31af17b0660","placeholder":"​","style":"IPY_MODEL_7653bb5066a641fd9f9460e8a0ba9a9c","value":" 440M/440M [00:07&lt;00:00, 34.3MB/s]"}},"47b492f17b554b4ca54cc2a73f513872":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"553e4c290bf442499971d293d9b51ae2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2602765530cc477aaefa2a609aa83e68","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_47b492f17b554b4ca54cc2a73f513872","value":231508}},"57431a90f3e447e98518973a7cb48c07":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_18948547f6b3494487cdd01a4e4ef40f","placeholder":"​","style":"IPY_MODEL_795090105206442dbecd9be390c79c01","value":" 28.0/28.0 [00:00&lt;00:00, 1.63kB/s]"}},"681bf438ba224d32a824bb2331827b64":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6c139070deaa4927a5f6d8ac34065cf0":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6f6f3426be5f421eb0265274021791ec":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d99d91ac49541a5abfa34be93a6c893","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fdea909831df49329811bf23b60c390d","value":440473133}},"7653bb5066a641fd9f9460e8a0ba9a9c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"795090105206442dbecd9be390c79c01":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7cb945c0f6854e8091736b96c9ce80d9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7d24ad7402a54f99ace407a8636b075e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7e5f69d9c7684857bded76c6fea9ebba":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dfc4b9f437324ae8aaa8279571f0cafb","IPY_MODEL_553e4c290bf442499971d293d9b51ae2","IPY_MODEL_f8238db21d4f456ca81a0095269a79a9"],"layout":"IPY_MODEL_356c151b038c4ddd827fc6fc7ccceb35"}},"864539d99caf439f9cbdc6c71777502e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a4a8c2aad378492d87bd5d34bbe09c71","IPY_MODEL_0989e4870fb841e39037a72a11751e86","IPY_MODEL_57431a90f3e447e98518973a7cb48c07"],"layout":"IPY_MODEL_c1dc87cf80174e94beda03713900d47f"}},"87beb12ec22a433f8c536ae39759244a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a2d9f0de4064791ab8ede7140e37e4c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2008e9e839f74eefb4e456b74a4ed8db","placeholder":"​","style":"IPY_MODEL_b53dcd103db54ab28e675e5f739c74cc","value":" 570/570 [00:00&lt;00:00, 30.7kB/s]"}},"8d99d91ac49541a5abfa34be93a6c893":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8eb800a03d0e47e79dd790b08db191e5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a146bfcfbd464397a8fee3cab82b25b1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b44b6301f7094dabb50f455e65c19bb1","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a42bb6d71aa343c5adb92fc1ced2b694","value":570}},"a42bb6d71aa343c5adb92fc1ced2b694":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a4a8c2aad378492d87bd5d34bbe09c71":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa1a6136434f46a68e787410b4101991","placeholder":"​","style":"IPY_MODEL_6c139070deaa4927a5f6d8ac34065cf0","value":"Downloading: 100%"}},"b44b6301f7094dabb50f455e65c19bb1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b53dcd103db54ab28e675e5f739c74cc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"beb26ac9783b4619bfcc8271bf196757":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0ca6457b9991475b9da90b3c21710370","IPY_MODEL_6f6f3426be5f421eb0265274021791ec","IPY_MODEL_422990b585a74174bdf99865c56ccd53"],"layout":"IPY_MODEL_166cb4fb73944407be4145d3c9a3c691"}},"c1dc87cf80174e94beda03713900d47f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c857146f435247658cb6e72f82f48715":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2eba24d68f4347da919c7c0e7665c4ab","placeholder":"​","style":"IPY_MODEL_cfe5b4060c124dbbb647e34fb590661a","value":"Downloading: 100%"}},"cfe5b4060c124dbbb647e34fb590661a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7acd4a9f756495bb73c4f81843c7c01":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d847035518044d78b1a4942907cfa2f9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dfc4b9f437324ae8aaa8279571f0cafb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5e43ab17bf04256a57146f0ee4d20d3","placeholder":"​","style":"IPY_MODEL_d7acd4a9f756495bb73c4f81843c7c01","value":"Downloading: 100%"}},"e27a087398244656979bc31af17b0660":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e5e43ab17bf04256a57146f0ee4d20d3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8238db21d4f456ca81a0095269a79a9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7d24ad7402a54f99ace407a8636b075e","placeholder":"​","style":"IPY_MODEL_681bf438ba224d32a824bb2331827b64","value":" 232k/232k [00:00&lt;00:00, 4.71MB/s]"}},"fa1a6136434f46a68e787410b4101991":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fdea909831df49329811bf23b60c390d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ee72ae874db64ab8bfe8ee225404db23":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c981ba65423d430ab4134eaaf7224fa8","IPY_MODEL_2671e9ceda0247838cdd66d720afd440","IPY_MODEL_b98a939c00e64f7e8593e0f14943a957"],"layout":"IPY_MODEL_fde6a0c54c2f4caa95d5c1b2a1946316"}},"c981ba65423d430ab4134eaaf7224fa8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dd9c5c230fe244a492c2e3918cde9ad6","placeholder":"​","style":"IPY_MODEL_1b2f38703a6c4f39987aec236418d877","value":"100%"}},"2671e9ceda0247838cdd66d720afd440":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6a239a5008f4467d9d4499dfc7290926","max":5572,"min":0,"orientation":"horizontal","style":"IPY_MODEL_503b78115fca442f8129d76bdeae1332","value":5572}},"b98a939c00e64f7e8593e0f14943a957":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0290fd67c67a4001b3641487c2b3d459","placeholder":"​","style":"IPY_MODEL_da98e22a205541a494bdbc021ccb2be5","value":" 5572/5572 [00:07&lt;00:00, 935.70ex/s]"}},"fde6a0c54c2f4caa95d5c1b2a1946316":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dd9c5c230fe244a492c2e3918cde9ad6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b2f38703a6c4f39987aec236418d877":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6a239a5008f4467d9d4499dfc7290926":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"503b78115fca442f8129d76bdeae1332":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0290fd67c67a4001b3641487c2b3d459":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da98e22a205541a494bdbc021ccb2be5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}